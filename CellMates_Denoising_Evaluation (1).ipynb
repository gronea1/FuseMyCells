{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44f1b792-379a-4788-acca-66edf3ea7509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageSequence\n",
    "import cv2\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage import filters\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import jaccard_score\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85cf75b4-73e6-4015-8e9e-8fff226660ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_stack(path):\n",
    "    frames = []\n",
    "    with Image.open(path) as img:\n",
    "        for frame in ImageSequence.Iterator(img):\n",
    "            image = np.array(frame)\n",
    "            frames.append(image)\n",
    "    return np.array(frames)\n",
    "\n",
    "def denoise_image_stack(image_stack, gaussian_sigma=1.0, median_size=3):\n",
    "    denoised_frames = []\n",
    "    for i, image in enumerate(image_stack):\n",
    "        image_min, image_max = np.min(image), np.max(image)\n",
    "        image = median_filter(image, size=median_size)\n",
    "        image = filters.gaussian(image, sigma=gaussian_sigma, preserve_range=True)\n",
    "\n",
    "        image_norm = (image - image_min) / (image_max - image_min)\n",
    "        image_norm = image_norm.astype(np.float32)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        d = max(5, min(height, width) // 50)\n",
    "        sigmaColor = np.std(image_norm) * 0.15\n",
    "        sigmaSpace = d * 1\n",
    "\n",
    "        image_filtered = cv2.bilateralFilter(image_norm, d, sigmaColor, sigmaSpace)\n",
    "\n",
    "        image_filtered = image_filtered * (image_max - image_min) + image_min\n",
    "        image_filtered = np.clip(image_filtered, 0, 65535)\n",
    "\n",
    "        out_dtype = np.uint16 if image_max > 255 else np.uint8\n",
    "        final_frame = image_filtered.astype(out_dtype)\n",
    "        denoised_frames.append(final_frame)\n",
    "\n",
    "        #print(f\"Processed slice {i+1}/{len(image_stack)}\")\n",
    "    return np.array(denoised_frames)\n",
    "\n",
    "def fuse_stack(image_stack, method='max'):\n",
    "    if method == 'max':\n",
    "        return np.max(image_stack, axis=0)\n",
    "    elif method == 'sum':\n",
    "        return np.clip(np.sum(image_stack, axis=0), 0, 65535)\n",
    "    elif method == 'average':\n",
    "        return np.clip(np.mean(image_stack, axis=0), 0, 65535)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown fusion method. Use 'max', 'sum', or 'average'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcb3806f-6464-468f-a583-d0af414cd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageSequence\n",
    "import cv2\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage import filters\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load image stack\n",
    "def load_image_stack(path):\n",
    "    frames = []\n",
    "    with Image.open(path) as img:\n",
    "        for frame in ImageSequence.Iterator(img):\n",
    "            image = np.array(frame)\n",
    "            frames.append(image)\n",
    "    return np.array(frames)\n",
    "\n",
    "# Function to denoise image stack\n",
    "def denoise_image_stack(image_stack, gaussian_sigma=1.0, median_size=3):\n",
    "    denoised_frames = []\n",
    "    for i, image in enumerate(image_stack):\n",
    "        image_min, image_max = np.min(image), np.max(image)\n",
    "        image = median_filter(image, size=median_size)\n",
    "        image = filters.gaussian(image, sigma=gaussian_sigma, preserve_range=True)\n",
    "\n",
    "        image_norm = (image - image_min) / (image_max - image_min)\n",
    "        image_norm = image_norm.astype(np.float32)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        d = max(5, min(height, width) // 50)\n",
    "        sigmaColor = np.std(image_norm) * 0.15\n",
    "        sigmaSpace = d * 1\n",
    "\n",
    "        image_filtered = cv2.bilateralFilter(image_norm, d, sigmaColor, sigmaSpace)\n",
    "\n",
    "        image_filtered = image_filtered * (image_max - image_min) + image_min\n",
    "        image_filtered = np.clip(image_filtered, 0, 65535)\n",
    "\n",
    "        out_dtype = np.uint16 if image_max > 255 else np.uint8\n",
    "        final_frame = image_filtered.astype(out_dtype)\n",
    "        denoised_frames.append(final_frame)\n",
    "\n",
    "    return np.array(denoised_frames)\n",
    "\n",
    "# Function to fuse image stack\n",
    "def fuse_stack(image_stack, method='max'):\n",
    "    if method == 'max':\n",
    "        return np.max(image_stack, axis=0)\n",
    "    elif method == 'sum':\n",
    "        return np.clip(np.sum(image_stack, axis=0), 0, 65535)\n",
    "    elif method == 'average':\n",
    "        return np.clip(np.mean(image_stack, axis=0), 0, 65535)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown fusion method. Use 'max', 'sum', or 'average'.\")\n",
    "\n",
    "# Function to resize images to match\n",
    "def resize_images_to_match(image1, image2):\n",
    "    \"\"\"\n",
    "    Resize image1 to match the dimensions of image2.\n",
    "    Ensures that both images are non-empty before attempting resizing.\n",
    "    \"\"\"\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both images are empty.\")\n",
    "    \n",
    "    # Resize image1 to match the shape of image2\n",
    "    return cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# Function to normalize image based on percentiles\n",
    "def percentile_normalization(image, pmin=2, pmax=99.8, axis=None):\n",
    "    if not (np.isscalar(pmin) and np.isscalar(pmax) and 0 <= pmin < pmax <= 100 ):\n",
    "        raise ValueError(\"Invalid values for pmin and pmax\")\n",
    "\n",
    "    low_percentile = np.percentile(image, pmin, axis=axis, keepdims=True)\n",
    "    high_percentile = np.percentile(image, pmax, axis=axis, keepdims=True)\n",
    "\n",
    "    if low_percentile == high_percentile:\n",
    "        print(f\"Same min {low_percentile} and high {high_percentile}, image may be empty\")\n",
    "        return image\n",
    "\n",
    "    return (image - low_percentile) / (high_percentile - low_percentile)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_fusion(fused_image, reference_image, input_image, do_normalize=True):\n",
    "    # Ensure images are the same shape by resizing\n",
    "    reference_image_resized = resize_images_to_match(reference_image, fused_image)\n",
    "    input_image_resized = resize_images_to_match(input_image, fused_image)\n",
    "\n",
    "    if do_normalize:\n",
    "        fused_image = percentile_normalization(fused_image)\n",
    "        reference_image_resized = percentile_normalization(reference_image_resized)\n",
    "\n",
    "    # Compute SSIM for input vs. reference (used for prediction SSIM)\n",
    "    input_ssim, _ = ssim(input_image_resized, reference_image_resized, full=True)\n",
    "\n",
    "    # Compute SSIM for fused vs. reference (used for reference SSIM)\n",
    "    fused_ssim, _ = ssim(fused_image, reference_image_resized, full=True)\n",
    "\n",
    "    # Compute normalized SSIM\n",
    "    n_ssim = (fused_ssim - input_ssim) / (1 - input_ssim)\n",
    "\n",
    "    # Compute PSNR\n",
    "    psnr_value = psnr(fused_image, reference_image_resized)\n",
    "\n",
    "    # Compute MSE\n",
    "    mse_value = mean_squared_error(fused_image.flatten(), reference_image_resized.flatten())\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Prediction SSIM : {input_ssim:.4f}\")\n",
    "    print(f\"Reference SSIM  : {fused_ssim:.4f}\")\n",
    "    print(f\"N SSIM          : {n_ssim:.4f}\")\n",
    "    print(f\"PSNR            : {psnr_value:.4f} dB\")\n",
    "    print(f\"MSE             : {mse_value:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"SSIM\": fused_ssim,\n",
    "        \"N SSIM\": n_ssim,\n",
    "        \"PSNR\": psnr_value,\n",
    "        \"MSE\": mse_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c09381a-f97e-401d-a469-82265a0c3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_side_by_side(image1, image2, title1='Image 1', title2='Image 2'):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(image1, cmap='gray')\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(image2, cmap='gray')\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8bddbf34-28db-4ef7-a93c-15fe709b6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Image 169 (nucleus) ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_fusion() got multiple values for argument 'do_normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m fused_reference \u001b[38;5;241m=\u001b[39m fuse_stack(reference_stack, method\u001b[38;5;241m=\u001b[39mfusion_method)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the fusion\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m evaluate_fusion(fused_input, fused_reference, input_stack[\u001b[38;5;241m0\u001b[39m], reference_stack[\u001b[38;5;241m0\u001b[39m], do_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Visualize the fused and reference images\u001b[39;00m\n\u001b[0;32m     36\u001b[0m show_side_by_side(fused_input, fused_reference,\n\u001b[0;32m     37\u001b[0m                   title1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_tag\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Fused \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     38\u001b[0m                   title2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_tag\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate_fusion() got multiple values for argument 'do_normalize'"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "nucleus_ids = [169, 170, 173, 174, 177]\n",
    "membrane_ids = [171, 172, 175, 176, 179]\n",
    "base_dir = r\"C:\\Users\\gronea\\Box\\Fuse My Cells Challenge\\image_169-180\"\n",
    "fusion_method = 'max'\n",
    "\n",
    "for image_id in nucleus_ids + membrane_ids:\n",
    "    if image_id in nucleus_ids:\n",
    "        type_tag = \"nucleus\"\n",
    "    elif image_id in membrane_ids:\n",
    "        type_tag = \"membrane\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Processing Image {image_id} ({type_tag}) ===\")\n",
    "\n",
    "    input_path = os.path.join(base_dir, f\"image_{image_id}_{type_tag}_angle.tif\")\n",
    "    reference_path = os.path.join(base_dir, f\"image_{image_id}_{type_tag}_fused.tif\")\n",
    "\n",
    "    if not os.path.exists(input_path) or not os.path.exists(reference_path):\n",
    "        print(f\"Missing files for image {image_id}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load and process\n",
    "    input_stack = load_image_stack(input_path)\n",
    "    reference_stack = load_image_stack(reference_path)\n",
    "\n",
    "    denoised_stack = denoise_image_stack(input_stack)\n",
    "    fused_input = fuse_stack(denoised_stack, method=fusion_method)\n",
    "    fused_reference = fuse_stack(reference_stack, method=fusion_method)\n",
    "\n",
    "    # Evaluate the fusion\n",
    "    evaluation_results = evaluate_fusion(fused_input, fused_reference, input_stack[0], reference_stack[0], do_normalize=True)\n",
    "\n",
    "    # Visualize the fused and reference images\n",
    "    show_side_by_side(fused_input, fused_reference,\n",
    "                      title1=f'{type_tag.capitalize()} Fused {image_id}',\n",
    "                      title2=f'{type_tag.capitalize()} Reference {image_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca471e-94a6-4fad-bc1a-a7a6650265fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
